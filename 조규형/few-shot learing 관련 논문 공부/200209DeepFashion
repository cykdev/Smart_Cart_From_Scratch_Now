https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf

DeepFashion: Powerint Robust Clothes Recognition and with Rich Annotations.

Few-shot learning의 경우 이미지 유사도를 측정하는 것이 굉장히 중요한 부분이다.

그래서 이미지 유사도를 실제 산업에 사용한 예제와 데이터세트를 찾아보았다.

위 DeepFashion 논문은 해당 기술을 패션업계에 적용한 예이다.

패션이미지의 특징추출, 랜드마크 추출과 더불어 In-shop retrieval이라는 주제도 함께 다루었다..

In-shop retrieval의 경우 어떤 이미지내의 패션아이템과 가장 유사한 이미지 DB내의 패션아이템을 찾는 과제로 스마트 스캐너와 굉장히 비슷한 과제이다.

특이하게도 Deepfashion에선 SSD나 Yolo같은 계열의 object detection 모델을 사용한 것 같지 않다.

DeepFashion에선 이문제를 VGG-16 를 backbone network로 이미지내 랜드마크(팔, 목 다리등의 위치)를 탐지한후 이미지내 패션아이템의 특징을 추출하는 하나의 네트워크로 해결했다.

SSD 나 Yolo보다 더 간단한 네트워크 구조로 이 문제에 대한 해결방법을 제시한것이 흥미로웠다.

인터넷 검색을 좀더해보니 https://github.com/open-mmlab/mmfashion 에서 실제 코드가 구현되어있었다.

여기서 구현된 네트워크 구조 (파이토치로 작성되어있어 파이토치 공부를 조금했다.) 파악해야겠다.

궁금점: 랜드마크 디텍션을 SSD 나 YOLO아닌 VGG-16네트워크로 해결했다. 물론 SSD 나 YOLO도 모두 backbone 네트워크를 VGG-16사용할수 있지만
Deepfashion의 네트워크는 좀더 단순한 것 같다. 이게 어떻게 가능한지 모르겠다.. 실제 네트워크 구조가 어떠한지 봐야겠다.
